# dHCP Learning-based Surface Pipeline

This the **training** instruction for the dHCP deep learning (DL)-based surface pipeline.

## Installation

### Python/PyTorch/PyTorch3D

The training of the dHCP DL-based surface pipeline is based on Python/PyTorch/PyTorch3D. We recommend installing [Anaconda](https://www.anaconda.com/download) and use ```conda``` to install the dependencies. After installing the Anaconda, you can run 
```
. install.sh
```
to create a new virtual environment ```dhcp``` and install [PyTorch](https://pytorch.org/), [PyTorch3D](https://pytorch3d.org/), as well as other required Python packages in the environment.


### FreeSurfer
We use FreeSurfer to generate ground truth spheres for learning-based spherical projection. You can install [FreeSurfer](https://surfer.nmr.mgh.harvard.edu/) following the instructions.


## Training

### Cortical Surface Reconstruction
The codes for the training of cortical surface reconstruction are included in the folder ```./surface/```. We need to train four neural network models for WM/pial surfaces and left/right brain hemispheres. The training requires at least 12GB GPU memory.

#### Data Proprocessing
The training requires bias corrected T2 MRI and binary brain mask as the inputs, as well as the WM and pial surfaces as the ground truth. We assume the original data are in the following directories:

```
/YOUR_DATA
    /sub1
        /sub1_desc-restore_T2w.nii.gz
        /sub1_desc-brain_mask.nii.gz
        /sub1_hemi-left_pial.surf.gii
        /sub1_hemi-left_wm.surf.gii
        /sub1_hemi-right_pial.surf.gii
        /sub1_hemi-right_wm.surf.gii
    /sub2
        /...
    /sub3
        /...
    /...
```

Then you can preprocess the data by running
```
cd ./surface
python preprocess.py --orig_dir='/YOUR_DATA/'\
                     --save_dir='./surface/data/'\
                     --T2='_desc-restore_T2w.nii.gz'\
                     --mask='_desc-brain_mask.nii.gz'
```
where ```orig_dir``` is the directory containing the original data,  ```save_dir``` is the directory to save the processed data, ```T2``` and ```mask``` are the suffix of the input T2 images and brain masks. 

The preprocessing will split the original data into training/validation/testing data and save to ```./surface/data/```. The T2 image will be affinely aligned to the dHCP 40-week atlas and the cortical surfaces will be remeshed to 150k vertices for training.

#### WM Surface
To train the model for WM surface reconstruction, please run
```
python train.py --surf_type='wm'\
                --surf_hemi='left'\
                --tag='YOUR_TAG'\
                --device='cuda:0'\
                --n_epoch=200\
                --sigma=1.0\
                --w_nc=3.0\
                --w_edge=0.3
```
where ```surf_type```=['wm', 'pial'] is the type of the surface, ```surf_hemi```=['left','right'] is the brain hemisphere, ```tag``` is a str to identify different experiments, ```n_epoch``` is the total training epochs, ```sigma``` is the standard deviation for Gaussian filter, ```w_nc``` is the weight of normal consistency loss, and ```w_edge``` is the weight of the edge length loss.

All model checkpoints and training logs are saved to ```./surface/ckpts/```. After training WM surface reconstruction, select the model checkpoints with the best validation results and move them to 
```
./surface/model/model_hemi-left_wm.pt
./surface/model/model_hemi-right_wm.pt
```

#### Pial Surface
For the training of pial surface reconstruction, please run
```
python train.py --surf_type='pial'\
                --surf_hemi='left'\
                --tag='YOUR_TAG'\
                --device='cuda:0'\
                --n_epoch=200\
                --sigma=1.0\
                --w_nc=3.0\
                --w_edge=0.3
```

After training, move the best model checkpoints to 
```
./surface/model/model_hemi-left_pial.pt
./surface/model/model_hemi-right_pial.pt
```



### Spherical Projection
The codes for training spherical projection are in the ```./sphere/``` folder. We use FreeSurfer to inflate and project the predicted WM surfaces to spheres as the ground truth. The dataset can be generated by running:
```
cd ./sphere
. surface_to_sphere.sh
```
This will create GT spheres for train/valid/test data and left/right hemispheres, depending on the arguments in ```surface_to_sphere.sh```. The GT spheres will be saved to ```./sphere/data/```.

After generating the data, you can run the following code to train Spherical U-Net for spherical mapping:
```
python train.py --surf_hemi='left'\
                --tag='YOUR_TAG'\
                --device='cuda:0'\
                --n_epoch=200\
                --w_geo=2.0\
                --w_edge=1.0\
                --w_area=0.5
```
where ```w_geo```, ```w_edge``` and ```w_area``` are the weights of geodesic, edge and area distortions.

After training, move the best model checkpoints to 
```
./sphere/model/model_hemi-left_sphere.pt
./sphere/model/model_hemi-right_sphere.pt
```



### Cortical Ribbon
We also train a U-Net to predict the segmentation of cortical gray matter. The cortical ribbon is only used as the region of interest for the computation of myelin map once the T1 image is provided. The codes for training are included in ```./seg/```.

Suppose your dataset has the following structure:
```
/YOUR_DATA
    /sub1
        /sub1_desc-restore_T2w.nii.gz
        /sub1_desc-brain_mask.nii.gz
        /sub1_tissue_label.nii.gz
    /sub2
        /...
    /sub3
        /...
    /...
```
You can generate ground truth cortical ribbon segmentations by running
```
cd ./seg
python preprocess.py --orig_dir='/YOUR_DATA/'\
                     --save_dir='./seg/data/'\
                     --T2='_desc-restore_T2w.nii.gz'\
                     --seg='_tissue_label.nii.gz'\
                     --mask='_desc-brain_mask.nii.gz'
```
where the tag ```seg``` is the suffix of the tissue segmentation files. Then, the segmentation network can be trained by
```
python train.py --tag='YOUR_TAG'\
                --device='cuda:0'\
                --n_epoch=200
```
After training, move the best model checkpoints to 
```
./seg/model/model_seg.pt
```